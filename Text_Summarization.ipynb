{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b5fdc81-07bd-47e6-a3c0-9afb0f23d7ec",
   "metadata": {},
   "source": [
    "# <div style=\"text-align: center; background-color: white; font-family:'Poppins', sans-serif; color: black; padding: 20px; line-height: 2; border-bottom:4px solid black; overflow:hidden\"> Text summarization </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67dcc48-b0e8-4190-a070-2cdee6e17748",
   "metadata": {},
   "source": [
    "* Text summarization is a very important task in NLP. It either generate short summaries of long articles or extract the most important sentences from the text.\n",
    "* It is of two types: Extractive vs. Abstractive Summarization:\n",
    "* Extractive Summarization:\n",
    "\n",
    "    * In extractive summarization, the goal is to identify and extract important sentences directly from the original text. These sentences are chosen based on their relevance or importance, usually via methods like TF-IDF or Word2Vec. However, the summary consists of the exact sentences from the original text.\n",
    "    * Limitation: It doesn't produce new sentences or concepts. If you want to reduce the text size but maintain the meaning, this method alone may not work well.\n",
    "    * It's often done using techniques like TF-IDF (Term Frequency-Inverse Document Frequency) or Word2Vec embeddings. These methods help to extract the most relevant information from large amounts of text, making it more digestible.\n",
    "\n",
    "\n",
    "* Abstractive Summarization:\n",
    "\n",
    "    * Abstractive summarization involves generating new sentences that convey the same meaning as the original text, rather than simply extracting parts of it. This method typically uses advanced deep learning models, such as Transformers, to understand and paraphrase the content.\n",
    "    * Advantage: This method reduces the size of the text while preserving its core meaning, and it can produce more coherent summaries that are often more human-like.\n",
    "    \n",
    "    * Methods for Abstractive Summarization:\n",
    "        * Seq2Seq Models (with Attention Mechanism):\n",
    "        \n",
    "            * Traditional Sequence-to-Sequence (Seq2Seq) models with Attention mechanisms are widely used for abstractive summarization. The model is trained to map the input sequence (the original text) to a condensed sequence (the summary). The attention mechanism helps the model focus on the most relevant parts of the text.\n",
    "        * Transformer Models:\n",
    "        \n",
    "            * Modern state-of-the-art models like BERT (Bidirectional Encoder Representations from Transformers) or GPT-3/4 (Generative Pre-trained Transformers) are very good at abstractive summarization.\n",
    "            * The T5 (Text-to-Text Transfer Transformer) and BART (Bidirectional and Auto-Regressive Transformers) models are especially designed for text generation tasks like summarization and have shown excellent performance.\n",
    "        * Pre-trained Models:\n",
    "        \n",
    "            * Instead of training from scratch, you can use pre-trained models for summarization. Popular pre-trained models include BART, T5, and PEGASUS, which are optimized for tasks like summarization and text generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2417b5d-511f-46ce-9caa-744b24091658",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: white; font-family: 'Poppins', sans-serif; color: black; padding: 20px;font-size: 24px; line-height: 2; overflow:hidden\"> Extractive Summarization </div>\n",
    "\n",
    "### 1. Text Summarization with TF-IDF (Extractive Summarization)\n",
    "The idea of extractive summarization is to extract the most important sentences from the text. TF-IDF helps in identifying important terms in a document based on their frequency and their rarity across multiple documents.\n",
    "\n",
    "* We'll follow these steps:\n",
    "\n",
    "    * Preprocess the text.\n",
    "    * Calculate the TF-IDF for each word.\n",
    "    * Use the TF-IDF scores to rank and extract the most relevant sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffd67179-bfed-444a-8275-ea76792adc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d15274db-2969-4afe-8b67-b93dff76e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text\n",
    "sample_text = \"\"\"\n",
    "Natural language processing (NLP) is a field of artificial intelligence (AI) that enables computers to understand,\n",
    "interpret, and generate human language. It is an interdisciplinary field that draws from linguistics, computer science, \n",
    "and artificial intelligence. NLP is used in various applications, including machine translation, sentiment analysis, \n",
    "chatbots, and text summarization. NLP helps in extracting meaningful information from unstructured text data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0094b94d-680f-4d5a-b47b-dbd74763f949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\test\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the text\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove \"not\" from stopwords\n",
    "stop_words.discard('not')\n",
    "\n",
    "punctuations = string.punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d025e71-68d4-428c-b6f1-68dcf20dacc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\test\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\test\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b4e26d6-8c66-4a7a-8d2a-94176a1485c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import string\n",
    "\n",
    "def preprocess(text):\n",
    "    words = word_tokenize(text.lower())   # Word tokenization\n",
    "    words = [w for w in words if w not in stop_words and w not in string.punctuation]\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Sentence tokenization\n",
    "sentences = sent_tokenize(sample_text)\n",
    "\n",
    "# Preprocess each sentence\n",
    "processed_sentences = [preprocess(sentence) for sentence in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e81cd4ba-bb3a-4bb6-83ac-d17e44fb782c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nNatural language processing (NLP) is a field of artificial intelligence (AI) that enables computers to understand,\\ninterpret, and generate human language.',\n",
       " 'It is an interdisciplinary field that draws from linguistics, computer science, \\nand artificial intelligence.',\n",
       " 'NLP is used in various applications, including machine translation, sentiment analysis, \\nchatbots, and text summarization.',\n",
       " 'NLP helps in extracting meaningful information from unstructured text data.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a81c772-7930-4c9e-b740-e043158b818c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['natural language processing nlp field artificial intelligence ai enables computers understand interpret generate human language',\n",
       " 'interdisciplinary field draws linguistics computer science artificial intelligence',\n",
       " 'nlp used various applications including machine translation sentiment analysis chatbots text summarization',\n",
       " 'nlp helps extracting meaningful information unstructured text data']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3fdcd36-0036-4d60-a91d-3f0f678a2df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(processed_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5739a0d-3132-4f53-997e-47309b53b669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence scoring based on TF-IDF\n",
    "sentence_scores = tfidf_matrix.sum(axis=1).A1  # Get the sum of the TF-IDF scores for each sentence\n",
    "ranked_sentences = [(score, sentence) for score, sentence in zip(sentence_scores, sentences)]\n",
    "ranked_sentences = sorted(ranked_sentences, reverse=True, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "849d4e2b-4270-43f1-be3e-44023a8cc63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.5833285240010877,\n",
       "  '\\nNatural language processing (NLP) is a field of artificial intelligence (AI) that enables computers to understand,\\ninterpret, and generate human language.'),\n",
       " (3.440746222419363,\n",
       "  'NLP is used in various applications, including machine translation, sentiment analysis, \\nchatbots, and text summarization.'),\n",
       " (2.8110807898436923,\n",
       "  'It is an interdisciplinary field that draws from linguistics, computer science, \\nand artificial intelligence.'),\n",
       " (2.8012310403735534,\n",
       "  'NLP helps in extracting meaningful information from unstructured text data.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3ea541-8762-4312-8db8-eb6325368953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_matrix is a TF-IDF matrix, where:\n",
    "# Rows represent sentences.\n",
    "# Columns represent words (features).\n",
    "# The values in the matrix are TF-IDF scores for each word in a given sentence.\n",
    "# .sum(axis=1) → Sums up all the TF-IDF scores for each sentence.\n",
    "# .A1 → Converts the result from a NumPy matrix to a 1D NumPy array.\n",
    "# Now, sentence_scores contains a single score for each sentence, representing its importance based on TF-IDF\n",
    "\n",
    "\n",
    "# ranked_sentences is a list where each sentence is associated with its TF-IDF-based score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f580c27-ef55-4850-9f55-470574cca5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top 2 sentences as summary\n",
    "num_sentences = 2\n",
    "summary = [sentence for _, sentence in ranked_sentences[:num_sentences]]\n",
    "# Extracts only the sentence text (ignoring the score).\n",
    "# The _ is a placeholder for the TF-IDF score, which we don't need in the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ad5e755-4d1f-4787-94e1-ef2de9f6742d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "\n",
      "Natural language processing (NLP) is a field of artificial intelligence (AI) that enables computers to understand,\n",
      "interpret, and generate human language. NLP is used in various applications, including machine translation, sentiment analysis, \n",
      "chatbots, and text summarization.\n"
     ]
    }
   ],
   "source": [
    "# Print the summary\n",
    "print(\"\\nSummary:\")\n",
    "print(\" \".join(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac919e8-1ec5-4883-8a64-310c55376779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d09ba72-e247-48c9-9d21-0cf7bb52ea98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff21b42a-29d7-4464-8993-f12728ea6bf1",
   "metadata": {},
   "source": [
    "### 2. Text Summarization using Word2Vec (Advanced)\n",
    "While TF-IDF provides a way to identify important sentences based on word frequencies, Word2Vec embeddings represent words in a continuous vector space. This allows for semantic understanding. The Word2Vec model can capture relationships like similarity between words and their contexts. You can use Word2Vec embeddings to improve summarization, especially in capturing the meaning of sentences.\n",
    "\n",
    "* Steps to use Word2Vec for text summarization:\n",
    "    * Preprocess the text (same as TF-IDF).\n",
    "    * Train a Word2Vec model using the preprocessed text.\n",
    "    * Use the model to calculate the similarity of each sentence.\n",
    "    * Rank the sentences by similarity and extract the most relevant ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9632acaa-cf3a-4b05-9453-cd460673818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import string\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806a474a-8e15-4663-89aa-1b7d48e71c3a",
   "metadata": {},
   "source": [
    "If this throws error - then\n",
    "* Create a compatible environment: conda create -n nlp_env python=3.10\n",
    "* Activate it: conda activate nlp_env\n",
    "* Install required packages:\n",
    "    * pip install numpy==1.26.4\n",
    "    * pip install scipy==1.10.\n",
    "    * pip install gensim==4.3.2\n",
    "    * pip install nltk\n",
    "    * pip install scikit-learn\n",
    "\n",
    "\n",
    "* Install Jupyter Kernel for This Env\n",
    "    * pip install ipykernel\n",
    "    * python -m ipykernel install --user --name nlp_env --display-name \"Python (nlp_env)\n",
    "    * conda install notebook\n",
    "* Launch Jupyter (FROM THIS ENV) : jupyter notebook\n",
    "* Select CORRECT KERNEL : Kernel → Change Kernel → Python (nlp_env)\"\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe8f219-ddab-45be-827d-8d4058a9ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text\n",
    "sample_text = \"\"\"\n",
    "Natural language processing (NLP) is a field of artificial intelligence (AI) that enables computers to understand,\n",
    "interpret, and generate human language. It is an interdisciplinary field that draws from linguistics, computer science, \n",
    "and artificial intelligence. NLP is used in various applications, including machine translation, sentiment analysis, \n",
    "chatbots, and text summarization. NLP helps in extracting meaningful information from unstructured text data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "233c03a4-8b50-4b96-8747-ee611e0221a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import string\n",
    "\n",
    "def preprocess(text):\n",
    "    words = word_tokenize(text.lower())   # Word tokenization\n",
    "    words = [w for w in words if w not in stop_words and w not in string.punctuation]\n",
    "    return words\n",
    "\n",
    "# Sentence tokenization\n",
    "sentences = sent_tokenize(sample_text)\n",
    "\n",
    "# Preprocess each sentence\n",
    "processed_sentences = [preprocess(sentence) for sentence in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "347dc1c2-446d-468b-865c-ad025c82123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "model = gensim.models.Word2Vec(processed_sentences, vector_size=100, window=5, min_count=1, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a90a4fd0-c68d-4e81-8d09-f7fdcb53ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the average sentence vector\n",
    "def sentence_vector(sentence):\n",
    "    word_vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "\n",
    "# If there are valid word vectors, compute their mean (average) along axis=0. This results in a single vector representing the sentence\n",
    "# If none of the words in the sentence exist in the model, return a zero vector with the same size as the model's word embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe2aaeef-5881-486d-ad1d-7da55aa55475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentence vectors\n",
    "sentence_vectors = [sentence_vector(sentence) for sentence in processed_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f106355-0ccc-4c3d-a6b6-d8a8f3a8161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity matrix\n",
    "similarity_matrix = cosine_similarity(sentence_vectors)\n",
    "\n",
    "# Calculates cosine similarity between every pair of sentence vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd512050-f60d-4953-8914-a4f07a1d3b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000001 ,  0.27345452,  0.2209907 ,  0.18821998],\n",
       "       [ 0.27345452,  0.99999994,  0.11778174, -0.0738035 ],\n",
       "       [ 0.2209907 ,  0.11778174,  1.        ,  0.2206038 ],\n",
       "       [ 0.18821998, -0.0738035 ,  0.2206038 ,  1.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "104ca562-19ec-4859-8bcd-db8abf58b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the average similarity of each sentence to all others\n",
    "sentence_scores = similarity_matrix.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eae85fa7-2709-464d-a16e-f620702ffa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentences = [(score, sentence) for score, sentence in zip(sentence_scores, sentences)]\n",
    "ranked_sentences = sorted(ranked_sentences, reverse=True, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a527776-1809-4276-a81c-d4ef61b0d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract top 2 sentences for the summary\n",
    "top_n = 2\n",
    "summary = [sentence for _, sentence in ranked_sentences[:top_n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c842d2db-db0b-4323-b549-ba4732430958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "\n",
      "Natural language processing (NLP) is a field of artificial intelligence (AI) that enables computers to understand,\n",
      "interpret, and generate human language. NLP is used in various applications, including machine translation, sentiment analysis, \n",
      "chatbots, and text summarization.\n"
     ]
    }
   ],
   "source": [
    "# Print the summary\n",
    "print(\"\\nSummary:\")\n",
    "print(\" \".join(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff81bf23-7cfc-47ae-87a3-bbc488a9d205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0dd19c-ae8b-49e5-94f7-25a3855eb6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp-env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
